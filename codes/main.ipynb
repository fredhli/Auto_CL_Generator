{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job-Spefecific Info Here\n",
    "Change this section every time  \n",
    "Close PDF Reader APP to avoid error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = \"\"\"\n",
    "About the job\n",
    "Requisition ID: 210955\n",
    "\n",
    "Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.\n",
    "\n",
    "Purpose\n",
    "\n",
    "Contributes to the overall success of the GWO Commodities Operations team globally ensuring specific\n",
    "\n",
    "individual goals, plans, initiatives are executed / delivered in support of the team's business strategies and\n",
    "\n",
    "objectives. Ensures all activities conducted are in compliance with governing regulations, internal policies and\n",
    "\n",
    "procedures.\n",
    "\n",
    "Is this role right for you? In this role, you will:\n",
    "\n",
    " Champions a customer focused culture to deepen client relationships and leverage broader Bank\n",
    "\n",
    "relationships, systems and knowledge.\n",
    "\n",
    " Ensures timely confirmation of trades by tracking unmatched transactions across numerous\n",
    "\n",
    "workstations and participates in root cause analysis to determine if mitigating processes are possible.\n",
    "\n",
    " Ensure efficient and effective daily settlement and confirmation operation process.\n",
    " Provides flexible support for daily operational workstation coverage across the department and offers\n",
    "\n",
    "feedback to management during workstation design initiatives.\n",
    "\n",
    " Understands internal control procedures and provides feedback to management to ensure controls\n",
    "\n",
    "remain relevant and robust.\n",
    "\n",
    " Understand how the Bank's risk appetite and risk culture should be considered in day-to-day activities\n",
    "\n",
    "and decisions.\n",
    "\n",
    " Actively pursues effective and efficient operations of his/her respective areas, while ensuring the\n",
    "\n",
    "adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with\n",
    "\n",
    "respect to operational risk, regulatory compliance risk, AML/ATF risk and conduct risk, including but not\n",
    "\n",
    "limited to responsibilities under the Operational Risk Management Framework, Regulatory Compliance\n",
    "\n",
    "Risk Management Framework, AML/ATF Global Handbook and the Guidelines for Business Conduct.\n",
    "\n",
    " Champions a high performance environment and implements a people strategy that attracts, retains,\n",
    "\n",
    "develops and motivates their team by fostering an inclusive work environment; communicating\n",
    "\n",
    "vison/values/business strategy and managing succession and development planning for the team.\n",
    "\n",
    "Skills\n",
    "\n",
    "Do you have the skills that will enable you to succeed in this role? – We'd love to work with you if you have:\n",
    "\n",
    " Strong knowledge of all Bank policies, regulatory requirements, limits and controls which may\n",
    "\n",
    "affect or restrict all aspects of the day-to-day responsibilities for the unit.\n",
    "\n",
    " Solid grasp of principles of all operating systems and applications used by the unit.\n",
    "\n",
    "Work Arrangement\n",
    "\n",
    " Work in a standard office-based environment; non-standard hours are a common occurrence. Travel may be required\n",
    "\n",
    "on an exception basis\n",
    "\n",
    "Interested?\n",
    "\n",
    "At Scotiabank, every employee is empowered to reach their fullest potential, respected for who they are and, embraced for their differences. That is why we work to grow and diversify talent and engage employees in a performance-oriented culture.\n",
    "\n",
    "What's in it for you?\n",
    "\n",
    "Scotiabank wants you to be able to bring your best self to work – and life, every day. With a focus on holistic well-being, our many flexible benefit programs are designed to help support your unique family, financial, physical, mental, and social health needs.\n",
    "\n",
    "Location(s): Canada : Ontario : Toronto\n",
    "\n",
    "Scotiabank is a leading bank in the Americas. Guided by our purpose: \"for every future\", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.\n",
    "\n",
    "At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.\n",
    "\"\"\"\n",
    "# Paste job description above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company info  \n",
    "You can leave the address blank, Google Map API will help you find the address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = \"Scotiabank\"\n",
    "company_address_line_1 = \"\"\n",
    "company_address_line_2 = \"\"\n",
    "company_city = \"Toronto\"\n",
    "company_state_two_letter = \"ON\"\n",
    "company_country = \"Canada\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal-specific Info\n",
    "Do you have anything else to stress in your cover letter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_strength_to_mention = \"\"\"\n",
    "- I have a Master's degree in Quantitative Finance and have worked on forecasting related projects.\n",
    "- Eligible to work in Canada without a sponsorship.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which version of CV do you want to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_type = \"trader\"\n",
    "# cv_type = \"equant_research\"\n",
    "# cv_type = \"operation\"\n",
    "# cv_type = \"risk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lihou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "c:\\Users\\lihou\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pyperclip\n",
    "import pandas as pd\n",
    "\n",
    "from config import *\n",
    "from cv_info import *\n",
    "from gpt_functions import *\n",
    "from gmap_functions import *\n",
    "from notion_functions import *\n",
    "\n",
    "from docx2pdf import convert\n",
    "from datetime import datetime\n",
    "from PyPDF2 import PdfFileReader, PdfFileWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Location and Version, change it in `cv_info.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_to_use = get_cv(cv_type)\n",
    "cv_location = cv_location(cv_folder, cv_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chromedriver Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_chromedriver, service, options = ready_for_chromedriver(\n",
    "    binary_location, path_to_chromedriver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = jd.replace(\"–\", \"-\").replace(\"'\", \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Company Location Straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_companyinfo = query_companyinfo(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = chatgpt(\"gpt-4o-mini\", prompt_companyinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    valid_info,\n",
    "    company_name,\n",
    "    company_address_line_1,\n",
    "    company_address_line_2,\n",
    "    company_city,\n",
    "    company_state_two_letter,\n",
    "    company_country,\n",
    ") = company_info(\n",
    "    info,\n",
    "    company_name,\n",
    "    company_address_line_1,\n",
    "    company_address_line_2,\n",
    "    company_city,\n",
    "    company_state_two_letter,\n",
    "    company_country,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Name: Scotiabank\n",
      "Company Address Line 1: None\n",
      "Company Address Line 2: None\n",
      "City: Toronto\n",
      "State: ON\n",
      "Country: Canada\n"
     ]
    }
   ],
   "source": [
    "print(f\"Company Name: {company_name}\")\n",
    "print(f\"Company Address Line 1: {company_address_line_1}\")\n",
    "print(f\"Company Address Line 2: {company_address_line_2}\")\n",
    "print(f\"City: {company_city}\")\n",
    "print(f\"State: {company_state_two_letter}\")\n",
    "print(f\"Country: {company_country}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Area if any mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info_test = info.replace(r\"\\n\\n\", r\"\\n\")\n",
    "# pattern = r\"\\*\\*Company Name:\\*\\*\\s*(.*?)\\s*\\n\\*\\*Company Address Line 1:\\*\\*\\s*(.*?)\\s*\\n\\*\\*Company Address Line 2:\\*\\*\\s*(.*?)\\s*\\n\\*\\*City:\\*\\*\\s*(.*?)\\s*\\n\\*\\*State:\\*\\*\\s*([A-Za-z]{2,})\\s*\"\n",
    "# results = re.match(pattern, info_test, re.DOTALL)\n",
    "# results.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_continue, info_type = judge_info_type(\n",
    "    company_name, company_address_line_1, company_address_line_2, company_city\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No address found, launching Google Maps search.\n"
     ]
    }
   ],
   "source": [
    "company_address_line_3 = \"\"\n",
    "\n",
    "if info_type == \"no_address\":\n",
    "    print(\"No address found, launching Google Maps search.\")\n",
    "    try:\n",
    "        company_address_line_1, company_address_line_2, company_address_line_3 = (\n",
    "            nearby_search_address(company_city, company_name, company_country)\n",
    "        )\n",
    "    except AssertionError:\n",
    "        beep(system_used)\n",
    "        company_address_line_1 = input(\n",
    "            \"No address found, please enter manually. Line 1: \"\n",
    "        )\n",
    "        beep(system_used)\n",
    "        company_address_line_2 = input(\"Please enter the address line 2: \")\n",
    "        if any(\n",
    "            x == \"\" for x in [company_city, company_state_two_letter, company_country]\n",
    "        ):\n",
    "            beep(system_used)\n",
    "            company_address_line_3 = input(\n",
    "                \"Please enter City, State Abbr, Country as line 3:\"\n",
    "            )\n",
    "        else:\n",
    "            company_address_line_3 = (\n",
    "                f\"{company_city}, {company_state_two_letter}, {company_country}\"\n",
    "            )\n",
    "\n",
    "if company_address_line_3 == \"\":\n",
    "    company_address_line_3 = (\n",
    "        f\"{company_city}, {company_state_two_letter}, {company_country}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check if we need to combine pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sthimportant = query_something_important(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "answer = chatgpt(\"gpt-4o-mini\", query_sthimportant)\n",
    "\n",
    "showed_popup_1 = judge_something_important(answer, package_folder, system_used)\n",
    "print(showed_popup_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Anything Super Urgent that will turn me down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_anything_turn_me_down = query_anything_turn_me_down(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "answer = chatgpt(\"gpt-4o-mini\", query_sthimportant)\n",
    "\n",
    "showed_popup_2 = judge_something_important(\n",
    "    answer, package_folder, system_used, turnmedown=True\n",
    ")\n",
    "print(showed_popup_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Any inportant keywords in JD that I did not mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATS Score: 85, you will pass this round of screening.\n"
     ]
    }
   ],
   "source": [
    "extract_status, ats_score, missing_kw_list = extract_keywords(\n",
    "    jd, cv_to_use, company_name, company_country\n",
    ")\n",
    "\n",
    "if not extract_status:\n",
    "    assert False, \"Keyword extraction failed. Please check the logs.\"\n",
    "\n",
    "elif ats_score >= 70:\n",
    "    print(f\"ATS Score: {ats_score}, you will pass this round of screening.\")\n",
    "\n",
    "else:\n",
    "    rec = show_popup_keyword(system_used, missing_kw_list, ats_score)\n",
    "    if rec == \"Decline suggestion\":\n",
    "        print(\"Process cancelled.\")\n",
    "    elif rec == \"Already changed\":\n",
    "        # shutil copy current cv to base.docx\n",
    "        shutil.copy(\n",
    "            cv_location.replace(\".pdf\", \".docx\"),\n",
    "            f\"{os.path.dirname(cv_location)}/base.docx\",\n",
    "        )\n",
    "        # Convert the docx file to pdf\n",
    "        base_docx_path = f\"{os.path.dirname(cv_location)}/base.docx\"\n",
    "        base_pdf_path = f\"{os.path.dirname(cv_location)}/base.pdf\"\n",
    "\n",
    "        # Convert the docx file to pdf\n",
    "        convert(base_docx_path, base_pdf_path)\n",
    "\n",
    "        # Read the PDF and keep only the first page\n",
    "        pdf_reader = PdfFileReader(base_pdf_path)\n",
    "        pdf_writer = PdfFileWriter()\n",
    "        pdf_writer.addPage(pdf_reader.getPage(0))\n",
    "\n",
    "        cv_path = f\"{os.path.dirname(cv_location)}/cv_with_keywords.pdf\"\n",
    "        with open(cv_path, \"wb\") as output_pdf:\n",
    "            pdf_writer.write(output_pdf)\n",
    "\n",
    "    else:\n",
    "        assert False, \"Invalid recommendation received.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Draft Cover Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amica Senior Lifestyles\n"
     ]
    }
   ],
   "source": [
    "print(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if company_name == \"\" or company_name == \"None\":\n",
    "    assert False, \"Company name is empty.\"\n",
    "\n",
    "prompt_cl = query_cover_letter(\n",
    "    cv_to_use, jd, company_name, additional_strength_to_mention\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chatgpt(\"chatgpt-4o-latest\", prompt_cl)\n",
    "match = re.search(\n",
    "    r\"Dear hiring manager,\\s*(.*)\\s*Sincerely,\", answer, re.DOTALL | re.IGNORECASE\n",
    ")\n",
    "\n",
    "if match:\n",
    "    extracted_text = match.group(1).strip()\n",
    "    pyperclip.copy(extracted_text)\n",
    "    print(\"The content has been copied to the clipboard.\")\n",
    "    print(\"\")\n",
    "    print(extracted_text)\n",
    "else:\n",
    "    print(\"The specified text was not found. Original answer:\")\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No need to shrink the text. The original text is already less than 300 words: 266 words.\n"
     ]
    }
   ],
   "source": [
    "extracted_text = shrink_text(extracted_text, threshold=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = len(extracted_text.split())\n",
    "word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Get my best Title for this Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_job_title = query_job_title(jd, cv_to_use, extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Data Scientist & Portfolio Manager**\n"
     ]
    }
   ],
   "source": [
    "job_title = chatgpt(\"chatgpt-4o-latest\", prompt_job_title)\n",
    "\n",
    "if \"*\" not in job_title:\n",
    "    job_title = \"**\" + job_title + \"**\"\n",
    "print(job_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found block with text: TBA Title\n",
      "Block 10ab1542-9002-80d4-abe7-ffca8866414d updated.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "replace_job_title_success, block_id = replace_simple(\"TBA Title\", job_title, page_id)\n",
    "print(replace_job_title_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found block with text: TBA Date\n",
      "Block b87e1d4a-c6af-4e91-bf93-e928c0c44dbe updated.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "today = datetime.today().strftime(\"%B %d, %Y\")\n",
    "replace_date_success, block_id = replace_simple(\"TBA Date\", today, page_id)\n",
    "print(replace_date_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "if info_type == \"single_line\":\n",
    "    parsed_address = f\"Hiring Manager\\n{company_address_line_1}\\n{company_name}\\n{company_address_line_3}\"\n",
    "elif info_type == \"no_address\":\n",
    "    parsed_address = f\"Hiring Manager\\n{company_address_line_1}\\n{company_address_line_2}\\n{company_address_line_3}\"\n",
    "elif info_type == \"full_address\":\n",
    "    parsed_address = f\"Hiring Manager\\n{company_address_line_1}\\n{company_address_line_2}\\n{company_city}, {company_state_two_letter}, {company_country}\"\n",
    "else:\n",
    "    assert False, \"Invalid info_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found block with text: TBA Address\n",
      "Block 10bb1542-9002-8099-a9a2-eb53beff1332 updated with color 'default'.\n"
     ]
    }
   ],
   "source": [
    "replace_address_success, block_id_address = replace_simple(\n",
    "    \"TBA Address\", parsed_address, page_id, change_color=True, color_to=\"default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found block with text: TBA Main Text\n",
      "Block 9b0acf97-d6e5-4d2d-bd28-12fab599edf9 updated.\n"
     ]
    }
   ],
   "source": [
    "replace_main_text_success, block_id_main = replace_simple(\n",
    "    \"TBA Main Text\", extracted_text.strip(), page_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No TBA found, page is successful.\n",
      "Page is successful, proceeding to download PDF.\n",
      "PDF saved to D:/Dropbox/Documents/JHt/Cover Letter/Cover Letter - Fred Li.pdf\n"
     ]
    }
   ],
   "source": [
    "download_success = selenium_download_pdf(service, options, download_folder, website)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 2 is blank. Removing...\n",
      "Saved PDF with 1 non-blank pages.\n"
     ]
    }
   ],
   "source": [
    "input_pdf_path = f\"{download_folder}/Cover Letter - {my_name}.pdf\"\n",
    "remove_blank_pages_from_pdf(input_pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy CV, CL to Package Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Dropbox/Documents/JHt/Cover Letter Backup/October 29, 2024_Amica Senior Lifestyles_Toronto.pdf'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy(cv_location, f\"{package_folder}/CV - {my_name}.pdf\")\n",
    "shutil.copy(\n",
    "    f\"{download_folder}/Cover Letter - {my_name}.pdf\",\n",
    "    f\"{package_folder}/Cover Letter - {my_name}.pdf\",\n",
    ")\n",
    "\n",
    "cl_backup_folder = f\"{root}/Cover Letter Backup\"\n",
    "shutil.copy(\n",
    "    f\"{package_folder}/Cover Letter - {my_name}.pdf\",\n",
    "    f\"{cl_backup_folder}/{today}_{company_name}_{company_city}.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all three PDFs in package folder\n",
    "\n",
    "if showed_popup_1 or showed_popup_2:\n",
    "    beep(system_used)\n",
    "    sequence = input(\n",
    "        \"Since GPT identified some modifications specefic to this JD, please enter the sequence of the PDFs to be combined, 1: CV; 2: CL; 3: Unofficial Transcript. e.g.: 123; 12; 13; 1, etc.\"\n",
    "    )\n",
    "else:\n",
    "    sequence = \"12\"\n",
    "\n",
    "merge_pdf(sequence, package_folder, my_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recover to Template for next use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found block with text: Data Scientist & Portfolio Manager\n",
      "Block 10ab1542-9002-80d4-abe7-ffca8866414d updated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, '10ab1542-9002-80d4-abe7-ffca8866414d')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_simple(job_title.replace(\"*\", \"\"), \"TBA Title\", page_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found block with text: October 29, 2024\n",
      "Block b87e1d4a-c6af-4e91-bf93-e928c0c44dbe updated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 'b87e1d4a-c6af-4e91-bf93-e928c0c44dbe')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_simple(today, \"TBA Date\", page_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found block with text: Hiring Manager\n",
      "Amica Senior Lifestyles Support Office\n",
      "16432\n",
      "Toronto, ON, Canada\n",
      "Block 10bb1542-9002-8099-a9a2-eb53beff1332 updated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, '10bb1542-9002-8099-a9a2-eb53beff1332')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_simple(company_address_line_1, \"TBA Address\", page_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated block 9b0acf97-d6e5-4d2d-bd28-12fab599edf9 with new text.\n",
      "Updated block 9b0acf97-d6e5-4d2d-bd28-12fab599edf9 with new text.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks = get_page_blocks(page_id)\n",
    "\n",
    "start_text = \"Dear Hiring Manager,\"\n",
    "end_text = \"Sincerely,\"\n",
    "replacement_text = \"TBA Main Text\"\n",
    "\n",
    "replace_text_in_blocks(blocks, start_text, end_text, replacement_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have the excel ready:\n",
    "\n",
    "# df = pd.DataFrame(\n",
    "#     columns=[\n",
    "#         'Date', 'Company_Name', 'Position_Name', 'Position_Name', 'CV_Used', 'Company_City', 'Company_State', 'Cover_Letter'\n",
    "#     ]\n",
    "# )\n",
    "# df.to_excel(f\"{root}/Application Tracker.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{root}/Application History.xlsx\", sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sentence = extracted_text.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_split = [\"role\", \"position\", \"job\", \"opening\"]\n",
    "role = \"\"\n",
    "\n",
    "for split_word in role_split:\n",
    "    if split_word in first_sentence.lower():\n",
    "        role_sentence = first_sentence.split(split_word)[0].strip()\n",
    "        word_pattern = r\"[A-Z][a-z]+\"\n",
    "        role_words = re.findall(word_pattern, role_sentence)\n",
    "        role = \" \".join(role_words)\n",
    "        break\n",
    "\n",
    "row = {\n",
    "    \"Date\": today,\n",
    "    \"Company Name\": company_name,\n",
    "    \"Position Name\": role,\n",
    "    \"Cover Letter\": f\"Cover Letter - {my_name}.pdf\",\n",
    "    \"CV Used\": cv_to_use,\n",
    "    \"Company City\": company_city,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_df = pd.DataFrame([row])\n",
    "df = pd.concat([df, row_df], ignore_index=True)\n",
    "df.fillna(\"\", inplace=True)\n",
    "df.drop_duplicates(subset=df.columns, keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(f\"{root}/Application History.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
